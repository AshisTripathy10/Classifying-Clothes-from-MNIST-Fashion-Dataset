Introduction: The objective of this project is to identify and categorize different fashion products from the given images of Fashion-MNIST data set using Machine Learning. Fashion-MNIST is a dataset of Zalando's article images —consisting of a training set of 60,000 examples and a test set of 10,000 examples. Each example is a 28x28 pixel image, associated with a label. The labels and their descriptions are the following:
    0         T-shirt/top
    1         Trouser 
    2         Pullover 
    3         Dress
    4         Coat
    5         Sandal 
    6         Shirt
    7         Sneaker
    8         Bag
    9         Ankle boot

Importing the Libraries: We import Numpy, Pandas, gzip, and Matplotlib.pyplot for the project. We define a showImage() function to display the input dataset image on the screen. It works by taking an image’s feature vector (1D array that represents the image), reshape it to a 28×28 array, and display it using Matplotlib’s imshow() function.

Loading the Data: The training dataset, training label, test dataset and test label are contained in 4 different files that are loaded separately using gzip. We use the showImage() to view the article image at index 0 of the Training dataset (ankle boot) and then view the corresponding label in the Target dataset (9)

Preparing the Dataset: We shuffle our training data using np.random.permutation() to ensure that we don't miss out any article in a cross validation fold. Further, each image in the dataset has 784 features and value of each feature ranges from 0 to 255, and this range is too wide , hence we would need to use feature scaling here to apply standardization to this dataset X_train, so that all the values of each feature pixel is in a small range (number of standard deviations away from mean). We use StandardScaler from SKLearn's preprocessing for the task

Training the Models: After data preparation, we train the following ML models: Softmax Regression (multi-class LogisticRegression), RandomForestClassifier, and Ensemble (with soft voting). We import accuracy_score, precision_score, recall_score and f1_score from SKLearn

Training Softmax Regression: We import Logistic Regression from SKLearn and create its instance with parameters - multi_class="multinomial" (handles multi-class classification using the softmax function), solver="lbfgs": (specifies the optimization algorithm to use) and C = 10 (sets the inverse of regularization strength). After training the model on the training dataset, we make the prediction on a sample instance and compare the prediction with the actual value. We then make the prediction on the whole training dataset and calculate - accuracy, precision, recall and F1 Score for Softmax Regression 

Training Random Forest Classifier: We import RandomForestClassifier from SKLearn. We create an instance of RandomForestClassifier by passing parameters - n_estimators=20 (number of trees), and max_depth=10 (max depth of each tree). After training the model on the training dataset, we make the prediction on a sample instance and compare the prediction with the actual value. We then make the prediction on the whole training dataset and calculate - accuracy, precision, recall and F1 Score for Softmax Regression 

Selecting the Model through Cross Validation: We randomly split the training set into 3 distinct subsets called folds (cv=3). Then we train and evaluate each model 3 times by picking a different fold for evaluation every time and training on the other 2 folds. The result is an array containing the evaluation scores for each of the measures - accuracy, precision, recall, and F1 score. We use the cross_val_score() function to calculate accuracy and use the cross_val_predict() function to create a confusion matrix to calculate Precision, Recall and F1 score.

Cross Validation - Softmax Regression: We import the modules cross_val_score and cross_val_predict from sklearn.model_selection and confusion_matrix from sklearn.metrics. We define a function display_scores() to  print the score value which is passed to it as argument, and also calculate and print the 'mean' and 'standard deviation' of this score. We perform k-fold cross-validation on the Softmax Regression model, and calculate the mean accuracy, precision, recall and F1 score values for the same. The scores are 0.847, 0.845, 0.847 and 0.846 respectively

Cross Validation - Random Forest Classifier: We follow the same steps for the Random Forest Classifier Model. The scores for  mean accuracy, precision, recall and F1 score are 0.848, 0.848, 0.848 and 0.845 respectively. We see that both the logistic regression and random forest have given the best results (nearly accuracy - 85%, standard deviation for accuracy - 0.002, Precision, Recall, F1 score nearly 0.85).

Dimensionality Reduction: Grid search for Hyperparameter tuning takes a lot of time on large datasets. Hence, we apply 'Dimensionality Reduction' to the training dataset to reduce the number of features, while ensuring it does not lead to any significant loss of information. We use Projection technique (PCA) for dimensionality reduction for our problem, which internally uses SVD (Singular Value Decomposition). We use the inverse_transform function to decompress the compressed dataset (X_train_reduced) back to 784 dimensions. With n_components =0.95 (number of components that capture at least 95% of the total variance in the original dataset), in the reduced dataset (X_train_reduced) we get only 187 features (out of original 784), and there is significant loss of information (quality) in the 'recovered' (decompressed) images. Hence, we select n_components=0.99, which gives 459 features (out of original 784) and there is no significant loss of information (quality) in the 'recovered' images. We use inverse_transform function to decompress the compressed dataset (X_train_reduced) back to 784 dimensions

Hyperparameter Tuning: We perform the Grid Search using the dimensionally reduced training dataset X_train_reduced. Our best model is Voting Classifier which is made up of two models: Logistic Regression and Random Forest. To do the grid search, we supply the various values of parameters for both of the underlying models. We import GridSearchCV, VotingClassifier, RandomForestClassifier, and LogisticRegression from SKLearn. For logistic regression, we try the following parameters: multi_class:["multinomial"], solver:["lbfgs"], C:[5]. For Random Forest, we try the following parameters: n_estimators:[20], max_depth:[10, 15]. We perform the Grid Search with 3 folds and run it on the 'reduced' training dataset X_train_reduced. We get the best hyperparameter values {'lr__C': 5, 'lr__multi_class': 'multinomial', 'lr__solver': 'lbfgs',  'rf__max_depth': 15,  'rf__n_estimators': 20} and the best estimator (a VotingClassifier that combines a LogisticRegression model with the above hyperparameters and a RandomForestClassifier with the above hyperparameters). The classifier uses soft voting, meaning it averages the predicted probabilities from both models to make the final prediction.

Evaluating Final Model on Test Dataset: We apply dimensionality reduction on the test dataset before we use it for prediction. We perform the predictions on the X_test_reduced dataset using the final model, and calculate various metrics scores like - accuracy, precision, recall, F1 score. They come out to be 0.847, 0.845, 0.847, 0.846. 

